# Human-AI Comparative Score (HACS) - HIB 1.0

## Overview
HACS is a benchmark domain designed to measure the "maturity" of AI responses compared to human cognitive baselines. Unlike traditional benchmarks that focus on accuracy or speed, HACS evaluates the **quality of reasoning, stability, and self-reflection**.

## Core Principles
1.  **Symmetry:** Every task must be solvable and relevant for both humans and AI.
2.  **Maturity over Intelligence:** We measure how "grown-up" (stable, neutral, reflective) the response is, not just raw IQ.
3.  **No "Gotchas":** Tasks are straightforward but require nuance.

## Modules
The benchmark consists of 5 modules (H1-H5) with a total of 70 questions.

- **H1: Meaning & Context** (15 Q): Understanding nuance and context.
- **H2: Bias Resilience** (15 Q): Maintaining neutrality under pressure.
- **H3: Knowledge Illusion** (15 Q): Distinguishing fact from fabrication.
- **H4: Reflection & Metacognition** (10 Q): Knowing what you don't know.
- **H5: Long-form Consistency** (15 Q): Staying on track over longer outputs.

## Scoring
Scoring is based on 6 universal criteria:
- Clarity
- Consistency
- Depth
- Neutrality
- Reflection
- Stability

Maturity is graded from **Unstable (0.0)** to **Mature (1.0)**.
